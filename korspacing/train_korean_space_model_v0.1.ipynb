{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845808ee",
   "metadata": {},
   "source": [
    "# 한국어 띄어쓰기 모델 학습 코드\n",
    "\n",
    "240625\n",
    "\n",
    "- [ref](https://github.com/haven-jeon/TrainKoSpacing.git)\n",
    "\n",
    "> git clone https://github.com/haven-jeon/TrainKoSpacing.git)\n",
    "\n",
    "- 완성, 학습중, pip 버전으로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f08a2",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f93a831",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## setup\n",
    "# pip intall torch==2.3.0\n",
    "# pip intall transformers==4.40.0\n",
    "# pip install gensim==4.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec76457",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66094/3007788194.py:23: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler, random_split\n",
    "import torch.nn.functional as F\n",
    "# from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "def seed_everything(random_seed=777):\n",
    "    # 모든 seed 고정\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "seed_everything(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3f3214f",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "## config\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='Korean Autospacing Trainer')\n",
    "    parser.add_argument('--num-epoch',\n",
    "                        type=int,\n",
    "                        default=20,\n",
    "                        help='number of iterations to train (default: 5)')\n",
    "\n",
    "    parser.add_argument('--n-hidden',\n",
    "                        type=int,\n",
    "                        default=200,\n",
    "                        help='GRU hidden size (default: 200)')\n",
    "\n",
    "    parser.add_argument('--max-seq-len',\n",
    "                        type=int,\n",
    "                        default=200,\n",
    "                        help='max sentence length on input (default: 200)')\n",
    "\n",
    "    parser.add_argument('--num-gpus',\n",
    "                        type=int,\n",
    "                        default=1,\n",
    "                        help='number of gpus (default: 1)')\n",
    "\n",
    "    parser.add_argument('--train',\n",
    "                        action='store_true',\n",
    "                        default=False,\n",
    "                        help='do trainig (default: False)')\n",
    "\n",
    "    parser.add_argument('--train-samp-ratio',\n",
    "                        type=float,\n",
    "                        default=0.5,\n",
    "                        help='random train sample ration (default: 0.50)')\n",
    "\n",
    "    parser.add_argument('--batch_size',\n",
    "                        type=int,\n",
    "                        default=100,\n",
    "                        help='train batch size')\n",
    "\n",
    "    parser.add_argument('--test_batch_size',\n",
    "                        type=int,\n",
    "                        default=100,\n",
    "                        help='test batch size')\n",
    "\n",
    "    parser.add_argument('--n_workers',\n",
    "                        type=int,\n",
    "                        default=10,\n",
    "                        help='number of dataloader workers')\n",
    "\n",
    "    parser.add_argument('--train_data',\n",
    "                        type=str,\n",
    "                        default='data/UCorpus_spacing_train.txt.bz2',\n",
    "                        help='bziped train data')\n",
    "\n",
    "    parser.add_argument('--test_data',\n",
    "                        type=str,\n",
    "                        default='data/UCorpus_spacing_test.txt.bz2',\n",
    "                        help='bziped test data')\n",
    "\n",
    "    parser.add_argument('--model_type',\n",
    "                        type=str,\n",
    "                        default='kospacing',\n",
    "                        help='kospacing or kospacing2')\n",
    "\n",
    "    parser.add_argument('--outputs',\n",
    "                        type=str,\n",
    "                        default='outputs',\n",
    "                        help='directory to save log and model params')\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "    return opt\n",
    "\n",
    "opt = get_parser()\n",
    "opt.bath_size = 64\n",
    "# opt.bath_size = 2\n",
    "# opt.sampling = 0.00101\n",
    "opt.sampling = 1\n",
    "opt.train_samp_ratio=0.95\n",
    "opt.make_lag_set = True  # n gram 8단어 이하로 데이터 증강 시도\n",
    "opt.learning_rate = 0.0001\n",
    "\n",
    "opt.SAVE_OUTPUT = './output_test'\n",
    "opt.vocab_file = './resources/w2idx.dic'\n",
    "opt.data_path_json = './data/train_corpus.txt'  # 학습 데이터, 1줄에 1문장으로 이루어진 txt파일로 구성\n",
    "opt.EPOCHS = 2\n",
    "\n",
    "# is_test = True\n",
    "is_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "940a50c4",
   "metadata": {
    "code_folding": [
     0,
     14,
     30,
     86,
     132,
     136,
     144,
     163,
     172,
     239,
     250,
     259
    ]
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "__all__ = [\n",
    "    'create_embeddings', 'load_embedding', 'load_vocab',\n",
    "    'encoding_and_padding', 'get_embedding_model'\n",
    "]\n",
    "\n",
    "import bz2\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def sent_to_spacing_chars(sent):\n",
    "    # 공백은 ^\n",
    "    chars = sent.strip().replace(' ', '^')\n",
    "    # char_list = [li.strip().replace(' ', '^') for li in sents]\n",
    "\n",
    "    # 문장의 시작 포인트 «\n",
    "    # 문장의 끌 포인트  »\n",
    "    tagged_chars = \"«\" + chars + \"»\"\n",
    "    # char_list = [ \"«\" + li + \"»\" for li in char_list]\n",
    "\n",
    "    # 문장 -> 문자열\n",
    "    char_list = ' '.join(list(tagged_chars))\n",
    "    # char_list = [ ' '.join(list(li))  for li in char_list]\n",
    "    return(char_list)\n",
    "\n",
    "\n",
    "def pad_sequences(sequences,\n",
    "                  maxlen=None,\n",
    "                  dtype='int32',\n",
    "                  padding='pre',\n",
    "                  truncating='pre',\n",
    "                  value=0.):\n",
    "\n",
    "    if not hasattr(sequences, '__len__'):\n",
    "        raise ValueError('`sequences` must be iterable.')\n",
    "    lengths = []\n",
    "    for x in sequences:\n",
    "        if not hasattr(x, '__len__'):\n",
    "            raise ValueError('`sequences` must be a list of iterables. '\n",
    "                             'Found non-iterable: ' + str(x))\n",
    "        lengths.append(len(x))\n",
    "\n",
    "    num_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((num_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if not len(s):\n",
    "            continue  # empty list/array was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' %\n",
    "                             truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError(\n",
    "                'Shape of sample %s of sequence at position %s is different from expected shape %s'\n",
    "                % (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_embeddings(data_dir,\n",
    "                      model_file,\n",
    "                      embeddings_file,\n",
    "                      vocab_file,\n",
    "                      splitc=' ',\n",
    "                      **params):\n",
    "    \"\"\"\n",
    "    making embedding from files.\n",
    "    :**params additional Word2Vec() parameters\n",
    "    :splitc   char for splitting in  data_dir files\n",
    "    :model_file output object from Word2Vec()\n",
    "    :data_dir data dir to be process\n",
    "    :embeddings_file numpy object file path from Word2Vec()\n",
    "    :vocab_file item to index json dictionary\n",
    "    \"\"\"\n",
    "    class SentenceGenerator(object):\n",
    "        def __init__(self, dirname):\n",
    "            self.dirname = dirname\n",
    "\n",
    "        def __iter__(self):\n",
    "            for fname in os.listdir(self.dirname):\n",
    "                print(\"processing~  '{}'\".format(fname))\n",
    "                for line in bz2.open(os.path.join(self.dirname, fname), \"rt\"):\n",
    "                    yield sent_to_spacing_chars(line.strip()).split(splitc)\n",
    "\n",
    "    sentences = SentenceGenerator(data_dir)\n",
    "\n",
    "    model = Word2Vec(sentences, **params)\n",
    "    model.save(model_file)\n",
    "    # model = Word2Vec.load(\"model_2.w2v\")\n",
    "    weights = model.wv.syn0\n",
    "    default_vec = np.mean(weights, axis=0, keepdims=True)\n",
    "    padding_vec = np.zeros((1, weights.shape[1]))\n",
    "\n",
    "    weights_default = np.concatenate([weights, default_vec, padding_vec],\n",
    "                                     axis=0)\n",
    "\n",
    "    np.save(open(embeddings_file, 'wb'), weights_default)\n",
    "\n",
    "    vocab = dict([(k, v.index) for k, v in model.wv.vocab.items()])\n",
    "    vocab['__ETC__'] = weights_default.shape[0] - 2\n",
    "    vocab['__PAD__'] = weights_default.shape[0] - 1\n",
    "    with open(vocab_file, 'w') as f:\n",
    "        f.write(json.dumps(vocab))\n",
    "\n",
    "\n",
    "def load_embedding(embeddings_file):\n",
    "    return (np.load(embeddings_file))\n",
    "\n",
    "\n",
    "def load_vocab(vocab_path):\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    word2idx = data\n",
    "    idx2word = dict([(v, k) for k, v in data.items()])\n",
    "    return word2idx, idx2word\n",
    "\n",
    "\n",
    "def encoding_and_padding(word2idx_dic, sequences, **params):\n",
    "    \"\"\"\n",
    "    1. making item to idx\n",
    "    2. padding\n",
    "    :word2idx_dic\n",
    "    :sequences: list of lists where each element is a sequence\n",
    "    :maxlen: int, maximum length\n",
    "    :dtype: type to cast the resulting sequence.\n",
    "    :padding: 'pre' or 'post', pad either before or after each sequence.\n",
    "    :truncating: 'pre' or 'post', remove values from sequences larger than\n",
    "        maxlen either in the beginning or in the end of the sequence\n",
    "    :value: float, value to pad the sequences to the desired value.\n",
    "    \"\"\"\n",
    "    seq_idx = [[word2idx_dic.get(a, word2idx_dic['__ETC__']) for a in i]\n",
    "               for i in sequences]\n",
    "    params['value'] = word2idx_dic['__PAD__']\n",
    "    return (pad_sequences(seq_idx, **params))\n",
    "\n",
    "\n",
    "def get_embedding_model(name='fee_prods', path='data/embedding'):\n",
    "    weights = pkg_resources.resource_filename(\n",
    "        'dsc', os.path.join(path, name, 'weights.np'))\n",
    "    w2idx = pkg_resources.resource_filename(\n",
    "        'dsc', os.path.join(path, name, 'idx.json'))\n",
    "    return ((load_embedding(weights), load_vocab(w2idx)[0]))\n",
    "\n",
    "\n",
    "\n",
    "def make_input_data(inputs,\n",
    "                    train_ratio,\n",
    "                    sampling,\n",
    "                    make_lag_set=False,\n",
    "                    batch_size=200):\n",
    "    with bz2.open(inputs, 'rt') as f:\n",
    "        line_list = [i.strip() for i in f.readlines() if i.strip() != '']\n",
    "    logger.info('complete loading train file!')\n",
    "\n",
    "    # 아버지가 방에 들어가신다. -> '«아버지가^방에^들어가신다.»'\n",
    "    processed_seq = pre_processing(line_list)\n",
    "    logger.info(processed_seq[0])\n",
    "    # n percent random sample\n",
    "    logger.info('random sampling on training set!')\n",
    "    samp_idx = np.random.choice(range(len(processed_seq)),\n",
    "                                int(len(processed_seq) * sampling),\n",
    "                                replace=False)\n",
    "    processed_seq_samp = [processed_seq[i] for i in samp_idx]\n",
    "    sp_sents = [i.split('^') for i in processed_seq_samp]\n",
    "\n",
    "    sp_sents = list(filter(lambda x: len(x) >= 8, sp_sents))\n",
    "\n",
    "    # max 8 어절 씩 1어절 shift하여 학습 데이터 생성\n",
    "    if make_lag_set is True:\n",
    "        n_gram = [[k, v, z, a, c, d, e, f]\n",
    "                  for sent in sp_sents for k, v, z, a, c, d, e, f in zip(\n",
    "                      sent, sent[1:], sent[2:], sent[3:], sent[4:], sent[5:],\n",
    "                      sent[6:], sent[7:])]\n",
    "    else:\n",
    "        n_gram = sp_sents\n",
    "    # max 200문자 이하만 사용\n",
    "    n_gram = [i for i in n_gram if len(\"^\".join(i)) <= opt.max_seq_len]\n",
    "    # y 정답 인코딩\n",
    "    n_gram_y = y_encoding(n_gram, opt.max_seq_len)\n",
    "    logger.info(n_gram[0])\n",
    "    logger.info(n_gram_y[0])\n",
    "    # vocab file 로딩\n",
    "    w2idx, _ = load_vocab(opt.vocab_file)\n",
    "\n",
    "    # 학습셋을 만들기 위해 공백을 제거하고 문자 인덱스로 인코딩함\n",
    "    logger.info('index eocoding!')\n",
    "    ngram_coding_seq = encoding_and_padding(\n",
    "        word2idx_dic=w2idx,\n",
    "        sequences=[''.join(gram) for gram in n_gram],\n",
    "        maxlen=opt.max_seq_len,\n",
    "        padding='post',\n",
    "        truncating='post')\n",
    "    logger.info(ngram_coding_seq[0])\n",
    "    if train_ratio < 1:\n",
    "        # 학습셋 테스트셋 생성\n",
    "        tr_idx, te_idx = split_train_set(ngram_coding_seq, train_ratio)\n",
    "\n",
    "        y_train = n_gram_y[tr_idx, ]\n",
    "        x_train = ngram_coding_seq[tr_idx, ]\n",
    "\n",
    "        y_test = n_gram_y[te_idx, ]\n",
    "        x_test = ngram_coding_seq[te_idx, ]\n",
    "\n",
    "        # train generator\n",
    "        train_generator = get_generator(x_train, y_train, batch_size)\n",
    "        valid_generator = get_generator(x_test, y_test, 500)\n",
    "        return (train_generator, valid_generator)\n",
    "    else:\n",
    "        train_generator = get_generator(ngram_coding_seq, n_gram_y, batch_size)\n",
    "        return (train_generator)\n",
    "\n",
    "\n",
    "def pre_processing(setences):\n",
    "    # 공백은 ^\n",
    "    char_list = [li.strip().replace(' ', '^') for li in setences]\n",
    "    # 문장의 시작 포인트 «\n",
    "    # 문장의 끌 포인트  »\n",
    "    char_list = [\"«\" + li + \"»\" for li in char_list]\n",
    "    # 문장 -> 문자열\n",
    "    char_list = [''.join(list(li)) for li in char_list]\n",
    "    return char_list\n",
    "\n",
    "\n",
    "def y_encoding(n_grams, maxlen=200):\n",
    "    # 입력된 문장으로 정답셋 인코딩함\n",
    "    # 띄어쓰기 위치에 1 채움\n",
    "    init_mat = np.zeros(shape=(len(n_grams), maxlen), dtype=np.int8)\n",
    "    for i in range(len(n_grams)):\n",
    "        init_mat[i, np.cumsum([len(j) for j in n_grams[i]]) - 1] = 1\n",
    "    return init_mat\n",
    "\n",
    "\n",
    "def split_train_set(x_train, p=0.98):\n",
    "    \"\"\"\n",
    "    > split_train_set(pd.DataFrame({'a':[1,2,3,4,None], 'b':[5,6,7,8,9]}))\n",
    "    (array([0, 4, 3]), [1, 2])\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    train_idx = np.random.choice(range(x_train.shape[0]),\n",
    "                                 int(x_train.shape[0] * p),\n",
    "                                 replace=False)\n",
    "    set_tr_idx = set(train_idx)\n",
    "    test_index = [i for i in range(x_train.shape[0]) if i not in set_tr_idx]\n",
    "    return ((train_idx, np.array(test_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f442f17",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 사전 파일 로딩\n",
    "w2idx, idx2w = load_vocab(opt.vocab_file)  # 1994, w2idx: '엠': 1352\n",
    "# 임베딩 파일 로딩\n",
    "vocab_size = 1994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ebefe6e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Sentence: 75\n",
      "['비 내린 직후에 따릉이를 타본 적 있는가.', \"십중팔구 '젖은 안장' 때문에 불편함을 겪었을 거다.\", '이유는 별다른 게 아니다.']\n"
     ]
    }
   ],
   "source": [
    "## get list of lines\n",
    "with open(opt.data_path_json, 'r', encoding='utf-8') as f_read:\n",
    "    lines = f_read.readlines()\n",
    "    list_sentence = [tmp.strip() for tmp in lines]\n",
    "    print(f'Num of Sentence: {len(list_sentence)}')\n",
    "print(list_sentence[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce4c717b",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비 내린 직후에 따릉이를 타본 적 있는가. \n",
      "=> «비^내린^직후에^따릉이를^타본^적^있는가.»\n",
      "## random sampling on training set!\n",
      "['«안장에', '물기가', '그대로', '남아', '있는', '경우가', '숱해서다.', '영찬씨는', '이렇게', '반문했다.»']\n",
      "['«안장에', '물기가', '그대로', '남아', '있는', '경우가', '숱해서다.', '영찬씨는']\n",
      "['«안장에', '물기가', '그대로', '남아', '있는', '경우가', '숱해서다.', '영찬씨는'] \n",
      "=> [0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "## index eocoding!\n",
      "['«안장에', '물기가', '그대로', '남아', '있는', '경우가', '숱해서다.', '영찬씨는'] \n",
      "=> [   3   94   54    7  116   19   11   17   31   15  156   26   30    6\n",
      "   87   63   11 1310   36   18    2    5  138  445  223    6 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 1993\n",
      " 1993 1993 1993 1993]\n"
     ]
    }
   ],
   "source": [
    "## data preprocessing\n",
    "# train data 선택, 8단어 이상 전처리\n",
    "# config\n",
    "# list_sentence\n",
    "# sampling = 0.001\n",
    "# make_lag_set = True\n",
    "# train_ratio = 0.90\n",
    "\n",
    "# 아버지가 방에 들어가신다. -> '«아버지가^방에^들어가신다.»'\n",
    "processed_seq = pre_processing(list_sentence)\n",
    "print(f'{list_sentence[0]} \\n=> {processed_seq[0]}')\n",
    "\n",
    "# n percent random sample\n",
    "print('## random sampling on training set!')\n",
    "# sapling ration 만큼 idx 선택\n",
    "samp_idx = np.random.choice(range(len(processed_seq)),\n",
    "                            int(len(processed_seq) * opt.sampling),\n",
    "                            replace=False)\n",
    "processed_seq_samp = [processed_seq[i] for i in samp_idx]\n",
    "sp_sents = [i.split('^') for i in processed_seq_samp]\n",
    "sp_sents = list(filter(lambda x: len(x) >= 8, sp_sents))  # 8단어 이상만 학습데이터로 선택\n",
    "print(f'{sp_sents[0]}')\n",
    "\n",
    "\n",
    "# max 8 어절 씩 1어절 shift하여 학습 데이터 생성, 긴 문장은 8어절씩 시프트 하여 데이터 쪼개기\n",
    "if opt.make_lag_set is True:\n",
    "    n_gram = [[k, v, z, a, c, d, e, f]\n",
    "              for sent in sp_sents for k, v, z, a, c, d, e, f in zip(\n",
    "                  sent, sent[1:], sent[2:], sent[3:], sent[4:], sent[5:],\n",
    "                  sent[6:], sent[7:])]\n",
    "else:\n",
    "    n_gram = sp_sents\n",
    "\n",
    "# max 200글자 이하만 사용\n",
    "n_gram = [i for i in n_gram if len(\"^\".join(i)) <= opt.max_seq_len]\n",
    "print(f'{n_gram[0]}')\n",
    "\n",
    "# y 정답 인코딩\n",
    "n_gram_y = y_encoding(n_gram, opt.max_seq_len)  # N, 200\n",
    "print(f'{n_gram[0]} \\n=> {n_gram_y[0]}')\n",
    "\n",
    "# vocab file 로딩\n",
    "w2idx, _ = load_vocab(opt.vocab_file)\n",
    "\n",
    "print('## index eocoding!')\n",
    "# 문장을 띄어쓰기 없이 이어부치고, char2idx를 수행, padding\n",
    "ngram_coding_seq = encoding_and_padding(\n",
    "    word2idx_dic=w2idx,\n",
    "    sequences=[''.join(gram) for gram in n_gram],\n",
    "    maxlen=opt.max_seq_len,\n",
    "    padding='post',\n",
    "    truncating='post')\n",
    "\n",
    "print(f'{n_gram[0]} \\n=> {ngram_coding_seq[0]}')\n",
    "\n",
    "\n",
    "## train/valid dataset\n",
    "# X: array([  98,  193,   52,   32,   15,   83,  371,   59,    2,   51,   25, 247,   36,    6,  415,   15,  332,   19,   96,  316,   28,   28, 29,   48,   44,  156,    7,  167,   98,   91, 1993, ..])\n",
    "# Y: array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, ..] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8a5b869",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size(train:valid:test) = 166:5:4\n",
      "Dataloader size with batch_size: 64 | (train:valid:test) = 3:1:1\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encoded_texts, tokenlevel_labels, original):\n",
    "        self.encoded_texts = encoded_texts\n",
    "        self.tokenlevel_labels = tokenlevel_labels\n",
    "        self.original = original\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        result = {\n",
    "            'X': torch.tensor(self.encoded_texts[idx], dtype=torch.long),\n",
    "#             'Y': torch.tensor(self.tokenlevel_labels[idx], dtype=torch.float),\n",
    "            'Y': torch.tensor(self.tokenlevel_labels[idx], dtype=torch.long),            \n",
    "            'original': ' '.join(self.original[idx])  # string으로\n",
    "        }\n",
    "        return result \n",
    "    \n",
    "    \n",
    "dataset = TextDataset(encoded_texts=ngram_coding_seq, tokenlevel_labels=n_gram_y, original=n_gram)  # 98.5가 100token\n",
    "\n",
    "\n",
    "if opt.train_samp_ratio < 1:\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    train_size = int(opt.train_samp_ratio * len(dataset))\n",
    "    test_size = (len(dataset) - train_size) // 2\n",
    "    val_size = len(dataset) - train_size - test_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "    print(f\"Dataset size(train:valid:test) = {len(train_dataset)}:{len(val_dataset)}:{len(test_dataset)}\")\n",
    "\n",
    "    # 데이터 로더 설정\n",
    "    train_loader = DataLoader(train_dataset, batch_size=opt.bath_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=opt.bath_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=opt.bath_size, shuffle=False)\n",
    "\n",
    "    print(f\"Dataloader size with batch_size: {opt.bath_size} | (train:valid:test) = {len(train_loader)}:{len(val_loader)}:{len(test_loader)}\")\n",
    "\n",
    "else:\n",
    "    train_dataset = dataset\n",
    "    print(f\"Dataset size(train:valid:test) = {len(train_dataset)}\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=opt.bath_size, shuffle=False)\n",
    "    print(f\"Dataloader size with batch_size: {opt.bath_size} | (train:valid:test) = {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10ca7655",
   "metadata": {
    "code_folding": [
     0,
     1,
     36,
     50,
     93
    ]
   },
   "outputs": [],
   "source": [
    "# CNN-LSTM 모델 정의\n",
    "class CNN_GRU_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_filters, filter_sizes, hidden_dim, output_dim, dropout):\n",
    "        super(CNN_GRU_Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(fs, embed_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        \n",
    "#         self.gru = nn.GRU(num_filters * len(filter_sizes), hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.lstm = nn.LSTM(num_filters * len(filter_sizes), hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 100)\n",
    "        self.fc2 = nn.Linear(100, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        cat = torch.cat(pooled, dim=1).unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        \n",
    "#         gru_out, _ = self.gru(cat)\n",
    "        gru_out, _ = self.lstm(cat)      \n",
    "        gru_out = self.dropout(gru_out)\n",
    "        \n",
    "        fc1_out = F.relu(self.fc1(gru_out))\n",
    "        output = torch.sigmoid(self.fc2(fc1_out)).squeeze(-1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim * 2, hidden_dim * 2, bias=False)\n",
    "        self.context_vector = nn.Linear(hidden_dim * 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, lstm_output):\n",
    "        attn_weights = torch.tanh(self.attention(lstm_output))\n",
    "        attn_weights = self.context_vector(attn_weights).squeeze(-1)\n",
    "        attn_weights = F.softmax(attn_weights, dim=1)\n",
    "        context_vector = attn_weights.unsqueeze(-1) * lstm_output\n",
    "        return context_vector, attn_weights\n",
    "\n",
    "\n",
    "class CNN_LSTM_Attention_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_filters, filter_sizes, hidden_dim, output_dim, dropout):\n",
    "        super(CNN_LSTM_Attention_Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(fs, embed_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        \n",
    "        self.lstm = nn.LSTM(num_filters * len(filter_sizes), hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 100)\n",
    "        self.fc2 = nn.Linear(100, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        cat = torch.cat(pooled, dim=1).unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(cat)\n",
    "        lstm_out = self.dropout(lstm_out)  # [64, 200, 256]\n",
    "        \n",
    "#         print(f'## 1\\n{lstm_out.shape}')\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(lstm_out)  # [64, 200, 256]\n",
    "        \n",
    "#         print(f'## 2\\n{context_vector.shape}')\n",
    "        \n",
    "        fc1_out = F.relu(self.fc1(context_vector))\n",
    "        output = torch.sigmoid(self.fc2(fc1_out)).squeeze(-1)  # [64, 200]\n",
    "        \n",
    "#         print(f'## 3\\n{output.shape}')\n",
    "        \n",
    "        return output  #, attention_weights\n",
    "    \n",
    "    \n",
    "class CharLevelLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes=1, num_layers=1, dropout=0.5):\n",
    "        super(CharLevelLSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embed_size)\n",
    "        x, (h_n, c_n) = self.lstm(x)  # (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Apply the fully connected layer to each time step\n",
    "        x = self.fc(x)  # (batch_size, seq_length, num_classes)\n",
    "        \n",
    "        return x.squeeze(-1)  # (batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9568c172",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "config_model_vocab_size = vocab_size\n",
    "config_model_embed_dim = 256\n",
    "config_model_num_filters = 128\n",
    "config_model_filter_sizes = [2, 3, 4, 5]  # 다양한 크기의 필터 사용\n",
    "config_model_hidden_dim = 256\n",
    "config_model_output_dim = 2  # binary\n",
    "config_model_dropout = 0.3\n",
    "config_model_num_layers = 3\n",
    "config_model_pad_token=1993  # padding 무시하고 loss를 구하기 위해\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:1\")# if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델, 손실 함수 및 옵티마이저 정의\n",
    "# model = CNN_GRU_Model(config_model_vocab_size, config_model_embed_dim, config_model_num_filters, config_model_filter_sizes, config_model_hidden_dim, config_model_output_dim, config_model_dropout)\n",
    "# model = CNN_LSTM_Attention_Model(config_model_vocab_size, config_model_embed_dim, config_model_num_filters, config_model_filter_sizes, config_model_hidden_dim, config_model_output_dim, config_model_dropout)\n",
    "model = CharLevelLSTM(config_model_vocab_size, config_model_embed_dim, config_model_hidden_dim, config_model_output_dim, config_model_num_layers, config_model_dropout)\n",
    "\n",
    "model.to(device);\n",
    "# criterion = nn.BCELoss()\n",
    "# class_weights = torch.tensor([3.85]).to(device)  # 클래스 불균형 해결을 위한 가중치 (예시 값)\n",
    "# class_weights = torch.tensor([3.6]).to(device)  # 클래스 불균형 해결을 위한 가중치 (예시 값)\n",
    "# criterion = nn.BCEWithLogitsLoss(reduction='none', pos_weight=class_weights)  #\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=pad_token)  # Set ignore_index to the padding token index\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.tensor([1, 10], dtype=torch.float).to(device), ignore_index=config_model_pad_token)  # Set ignore_index to the padding token index\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1, 3], dtype=torch.float).to(device), ignore_index=config_model_pad_token)  # Set ignore_index to the padding token index\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=opt.learning_rate, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "581b855c",
   "metadata": {
    "code_folding": [
     0,
     1,
     39
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Start Training ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#### Training F1: 0.0: 100%|███████████████████| 3/3 [00:00<00:00,  6.99it/s]\n",
      "#### 0: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 159.73it/s]\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## example ##\n",
      "«\"비가 내린 후에 따릉이 타보셨어요? 할 말이 없어요.\"\n",
      "label: [0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
      "pred  :[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Epoch 1/2\n",
      "Train Loss/Accuracy/F1: 0.6669/0.9600/0.4898\n",
      "Valid Loss/Accuracy/F1: 0.6354/0.9600/0.4898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       960\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.48      0.50      0.49      1000\n",
      "weighted avg       0.92      0.96      0.94      1000\n",
      "\n",
      "Best model saved at epoch 0, validation accuracy/f1: 0.96/0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#### Training F1: 0.0: 100%|███████████████████| 3/3 [00:00<00:00, 13.35it/s]\n",
      "#### 0: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 163.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## example ##\n",
      "«\"비가 내린 후에 따릉이 타보셨어요? 할 말이 없어요.\"\n",
      "label: [0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
      "pred  :[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Epoch 2/2\n",
      "Train Loss/Accuracy/F1: 0.6231/0.9600/0.4898\n",
      "Valid Loss/Accuracy/F1: 0.5895/0.9600/0.4898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       960\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.48      0.50      0.49      1000\n",
      "weighted avg       0.92      0.96      0.94      1000\n",
      "\n",
      "Best model saved at epoch 0, validation accuracy/f1: 0.49/0.49\n",
      "## Training Complete ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/go/anaconda3/envs/rag/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0.0\n",
    "    tmp_f1 = 0.0\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    for data in tqdm(train_loader, desc=f'#### Training F1: {tmp_f1}'):\n",
    "        inputs, labels, original = data['X'].to(device), data['Y'].to(device), data['original']\n",
    "        # inputs, labels: (N, seq_len)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)  # (N, seq_len, 2)\n",
    "        \n",
    "        ## 손실 계산\n",
    "        # cross entrophy 계산을 위해 outputs, labels는 [N, seq_len, Num_class] -> [N*seq_len, Num_class]\n",
    "        loss = criterion(outputs.view(-1, model.num_classes), labels.view(-1))# * mask  # 마스크를 적용하여 패딩 인덱스의 손실을 0으로 만듭니다\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy().flatten())\n",
    "        all_preds.extend(torch.argmax(outputs, dim=2).detach().cpu().numpy().flatten())  # (batch_size, seq_length)\n",
    "    \n",
    "        tmp_all_labels = [round(lbl) for lbl in all_labels]\n",
    "        tmp_all_preds = [round(pred) for pred in all_preds]        \n",
    "        tmp_f1 = f1_score(tmp_all_labels, tmp_all_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        if is_test:break\n",
    "        \n",
    "    all_labels = [round(lbl) for lbl in all_labels]\n",
    "    all_preds = [round(pred) for pred in all_preds]\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return total_loss / len(train_loader.dataset), accuracy, f1\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "    list_pred, list_labels, list_sentence = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(val_loader, desc=f'#### {total_loss}'):\n",
    "                \n",
    "            inputs, labels, original = data['X'].to(device), data['Y'].to(device), data['original']\n",
    "\n",
    "            outputs = model(inputs)  # [N, 200]\n",
    "            \n",
    "            # 손실 계산\n",
    "            # cross entrophy 계산을 위해 outputs, labels는 [N, seq_len, Num_class] -> [N*seq_len, Num_class]\n",
    "            loss = criterion(outputs.view(-1, model.num_classes), labels.view(-1))\n",
    "            \n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            val_labels.extend(labels.cpu().numpy().flatten())\n",
    "            val_preds.extend(torch.argmax(outputs, dim=2).cpu().numpy().flatten())  # (batch_size, seq_length)\n",
    "            \n",
    "            list_sentence.extend(data['original'])\n",
    "            list_pred.extend(torch.argmax(outputs, dim=2).cpu().numpy().tolist())\n",
    "            list_labels.extend(labels.cpu().numpy().tolist())            \n",
    "            \n",
    "            if is_test:break\n",
    "            \n",
    "    val_labels = [round(lbl) for lbl in val_labels]\n",
    "    val_preds = [round(pred) for pred in val_preds]\n",
    "        \n",
    "    accuracy = accuracy_score(val_labels, val_preds)\n",
    "    f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n",
    "    report = classification_report(val_labels, val_preds, output_dict=True)\n",
    "    report_string = classification_report(val_labels, val_preds, output_dict=False)\n",
    "\n",
    "    print(f'## example ##\\n{list_sentence[0]}\\nlabel: {list_labels[0][:10]}\\npred  :{list_pred[0][:10]}')\n",
    "    \n",
    "    return total_loss / len(val_loader.dataset), accuracy, f1, report, report_string\n",
    "\n",
    "# 초기화\n",
    "early_stop_best_f1, early_stop_best_accuracy, early_stop_best_loss = 0.0, 0.0, 0.0\n",
    "early_stop_patience = 10\n",
    "early_stop_patience_counter = 0\n",
    "early_stop_best_epoch = -1\n",
    "best_model_state_dict = None\n",
    "# 리스트 초기화\n",
    "list_train_loss, list_train_accuracy, list_train_f1, list_val_loss, list_val_accuracy, list_val_f1 = [], [], [], [], [], []\n",
    "\n",
    "if not os.path.exists(opt.SAVE_OUTPUT): os.makedirs(opt.SAVE_OUTPUT)\n",
    "\n",
    "# 모델 훈련 및 평가 루프\n",
    "print('## Start Training ##')  \n",
    "for epoch in range(opt.EPOCHS):\n",
    "    train_loss, train_accuracy, train_f1 = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_accuracy, val_f1, report, report_string = evaluate(model, val_loader, device)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}/{opt.EPOCHS}')\n",
    "    print(f'Train Loss/Accuracy/F1: {train_loss:.4f}/{train_accuracy:.4f}/{train_f1:.4f}')\n",
    "    print(f'Valid Loss/Accuracy/F1: {val_loss:.4f}/{val_accuracy:.4f}/{val_f1:.4f}')\n",
    "    print(report_string)\n",
    "\n",
    "    list_train_loss.append(train_loss)\n",
    "    list_train_accuracy.append(train_accuracy)\n",
    "    list_train_f1.append(train_f1)\n",
    "    list_val_loss.append(val_loss)\n",
    "    list_val_accuracy.append(val_accuracy)\n",
    "    list_val_f1.append(val_f1)\n",
    "    \n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_f1 > early_stop_best_f1:\n",
    "        early_stop_best_f1 = val_f1\n",
    "        early_stop_best_accuracy = val_accuracy\n",
    "        early_stop_best_loss = val_loss        \n",
    "        early_stop_best_epoch = epoch\n",
    "        early_stop_patience_counter = 0\n",
    "        \n",
    "        best_model_state_dict = model.state_dict()\n",
    "        torch.save(best_model_state_dict, os.path.join(opt.SAVE_OUTPUT, f'model_{early_stop_best_epoch}_{early_stop_best_f1:.2f}_{early_stop_best_f1:.2f}.pth'))\n",
    "        print(f\"Best model saved at epoch {early_stop_best_epoch}, validation accuracy/f1: {early_stop_best_accuracy:.2f}/{early_stop_best_f1:.2f}\")\n",
    "    \n",
    "    else:\n",
    "        early_stop_patience_counter += 1\n",
    "        if early_stop_patience_counter >= early_stop_patience:\n",
    "            print(f\"No improvement for {early_stop_patience} epochs. Early stopping...\")\n",
    "            break\n",
    "    \n",
    "    if early_stop_patience_counter >= early_stop_patience:\n",
    "        print(f'Early stopping at epoch {epoch}')\n",
    "        break\n",
    "\n",
    "# Best model 저장\n",
    "if best_model_state_dict is not None:\n",
    "    torch.save(model.state_dict(), os.path.join(opt.SAVE_OUTPUT, 'best_model.pth'))\n",
    "    model.load_state_dict(best_model_state_dict);  # Best 상태로 모델을 로드\n",
    "#     model.save_pretrained(opt.SAVE_OUTPUT);  # Transformers의 save_pretrained 메서드 사용\n",
    "#     tokenizer.save_pretrained(opt.SAVE_OUTPUT);  # 토크나이저 저장\n",
    "    print(f\"Best model saved at epoch {early_stop_best_epoch}, validation accuracy/f1: {early_stop_best_f1:.2f}/{early_stop_best_f1:.2f}\")\n",
    "else:\n",
    "    print(\"No improvement in validation accuracy.\")\n",
    "\n",
    "\n",
    "print('## Training Complete ##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90792aed",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(list_train_loss, label='Train Loss', color='blue')\n",
    "plt.plot(list_val_loss, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss')\n",
    "# 최저 손실값에 대한 지점 찾기\n",
    "best_loss_epoch = list_val_loss.index(min(list_val_loss))\n",
    "best_loss = min(list_val_loss)\n",
    "# 최저 손실값에 빨간 점 찍기\n",
    "plt.scatter(best_loss_epoch, best_loss, color='red', s=100, label=f'Best Loss({best_loss_epoch}): {best_loss:.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(list_train_f1, label='Train F1', color='blue')\n",
    "plt.plot(list_val_f1, label='Validation F1', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy')\n",
    "# 최저 손실값에 대한 지점 찾기\n",
    "best_accuracy_epoch = list_val_f1.index(max(list_val_f1))\n",
    "best_accuracy = max(list_val_f1)\n",
    "# 최저 손실값에 빨간 점 찍기\n",
    "plt.scatter(best_accuracy_epoch, best_accuracy, color='red', s=100, label=f'Best F1({best_accuracy_epoch}): {best_accuracy:.2f}%')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# 이미지 파일로 저장\n",
    "plt.savefig(os.path.join(opt.SAVE_OUTPUT, 'result.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36623f83",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a6b139f",
   "metadata": {
    "code_folding": [
     0,
     26
    ]
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "SAVE_OUTPUT = './output_test'\n",
    "# 하이퍼파라미터 설정\n",
    "config_model_vocab_size = 1994\n",
    "config_model_embed_dim = 256\n",
    "config_model_num_filters = 128\n",
    "config_model_filter_sizes = [2, 3, 4, 5]  # 다양한 크기의 필터 사용\n",
    "config_model_hidden_dim = 256\n",
    "config_model_output_dim = 2  # binary\n",
    "config_model_dropout = 0.3\n",
    "config_model_num_layers = 3\n",
    "config_model_pad_token=1993  # padding 무시하고 loss를 구하기 위해\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda:1\")# if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델, 손실 함수 및 옵티마이저 정의\n",
    "# CNN-LSTM 모델 정의\n",
    "class CharLevelLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes=1, num_layers=1, dropout=0.5):\n",
    "        super(CharLevelLSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embed_size)\n",
    "        x, (h_n, c_n) = self.lstm(x)  # (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Apply the fully connected layer to each time step\n",
    "        x = self.fc(x)  # (batch_size, seq_length, num_classes)\n",
    "        \n",
    "        return x.squeeze(-1)  # (batch_size, seq_length)\n",
    "\n",
    "model = CharLevelLSTM(config_model_vocab_size, config_model_embed_dim, config_model_hidden_dim, config_model_output_dim, config_model_num_layers, config_model_dropout)\n",
    "model.to(device);\n",
    "model.load_state_dict(torch.load(os.path.join(SAVE_OUTPUT, 'best_model.pth')));  # Best 상태로 모델을 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b943cd14",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## config\n",
    "root_folder = './resources'\n",
    "vocab_path = os.path.join(root_folder, 'w2idx.dic')\n",
    "model_path = os.path.join(opt.SAVE_OUTPUT, 'best_model.pth')\n",
    "max_seq_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93e87a6d",
   "metadata": {
    "code_folding": [
     0,
     1,
     12,
     31
    ]
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "def pre_processing(setences):\n",
    "    # 공백은 ^\n",
    "    char_list = [li.strip().replace(' ', '^') for li in setences]\n",
    "    # 문장의 시작 포인트 «\n",
    "    # 문장의 끌 포인트  »\n",
    "    char_list = [\"«\" + li + \"»\" for li in char_list]\n",
    "    # 문장 -> 문자열\n",
    "    char_list = [''.join(list(li)) for li in char_list]\n",
    "    return char_list\n",
    "\n",
    "\n",
    "def encoding_and_padding(word2idx_dic, sequences, **params):\n",
    "    \"\"\"\n",
    "    1. making item to idx\n",
    "    2. padding\n",
    "    :word2idx_dic\n",
    "    :sequences: list of lists where each element is a sequence\n",
    "    :maxlen: int, maximum length\n",
    "    :dtype: type to cast the resulting sequence.\n",
    "    :padding: 'pre' or 'post', pad either before or after each sequence.\n",
    "    :truncating: 'pre' or 'post', remove values from sequences larger than\n",
    "        maxlen either in the beginning or in the end of the sequence\n",
    "    :value: float, value to pad the sequences to the desired value.\n",
    "    \"\"\"\n",
    "    seq_idx = [[word2idx_dic.get(a, word2idx_dic['__ETC__']) for a in i]\n",
    "               for i in sequences]\n",
    "    params['value'] = word2idx_dic['__PAD__']\n",
    "    return (pad_sequences(seq_idx, **params))\n",
    "\n",
    "\n",
    "def load_vocab(vocab_path):\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    word2idx = data\n",
    "    idx2word = dict([(v, k) for k, v in data.items()])\n",
    "    return word2idx, idx2word\n",
    "\n",
    "\n",
    "# 사전 파일 로딩\n",
    "w2idx, idx2w = load_vocab(vocab_path)  # 1994, w2idx: '엠': 1352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fa6da06",
   "metadata": {
    "code_folding": [
     0,
     1,
     57,
     71
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아 버 지가 방에 들어 가 신다\n",
      "=>['«아버지가방에들어가신다»']\n",
      "=>아버지가방에들어가신다\n",
      "=>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "## 추론\n",
    "def pad_sequences(sequences,\n",
    "                  maxlen=None,\n",
    "                  dtype='int32',\n",
    "                  padding='pre',\n",
    "                  truncating='pre',\n",
    "                  value=0.):\n",
    "\n",
    "    if not hasattr(sequences, '__len__'):\n",
    "        raise ValueError('`sequences` must be iterable.')\n",
    "    lengths = []\n",
    "    for x in sequences:\n",
    "        if not hasattr(x, '__len__'):\n",
    "            raise ValueError('`sequences` must be a list of iterables. '\n",
    "                             'Found non-iterable: ' + str(x))\n",
    "        lengths.append(len(x))\n",
    "\n",
    "    num_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((num_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if not len(s):\n",
    "            continue  # empty list/array was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' %\n",
    "                             truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError(\n",
    "                'Shape of sample %s of sequence at position %s is different from expected shape %s'\n",
    "                % (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x\n",
    "\n",
    "# 추론 함수 정의\n",
    "def make_pred_sents(x_sents, y_pred):\n",
    "    res_sent = []\n",
    "    for i, j in zip(x_sents, y_pred):\n",
    "        if j == 1:\n",
    "            res_sent.append(i)\n",
    "            res_sent.append(' ')\n",
    "        else:\n",
    "            res_sent.append(i)\n",
    "    subs = re.sub(re.compile(r'\\s+'), ' ', ''.join(res_sent).replace('^', ' '))\n",
    "    subs = subs.replace('«', '')\n",
    "    subs = subs.replace('»', '')\n",
    "    return subs\n",
    "\n",
    "\n",
    "def inference(model, input_txt, device):\n",
    "    model.eval()\n",
    "    input_txt_processed = pre_processing([input_txt])  # ['«아버지가^방에^들어^가^신다»']\n",
    "    input_txt_processed_no_space = [tmp.replace('^', '') for tmp in input_txt_processed]  # ['«아버지가방에들어가신다»']\n",
    "    # input_txt_processed_no_space = [tmp for tmp in input_txt_processed]  # ['«아버지가방에들어가신다»']\n",
    "\n",
    "    input_txt_processed_indice = encoding_and_padding(word2idx_dic=w2idx,\n",
    "                                  sequences=input_txt_processed_no_space,\n",
    "                                  maxlen=max_seq_len,\n",
    "                                  padding='post',\n",
    "                                  truncating='post')  # [[   3,   26,  188,   12,   11,  118,    7,   29,   20,   11,   70, 2,   4, 1993, 1993,\n",
    "\n",
    "    # print(f'{input_txt_processed}\\n=>{input_txt_processed_no_space}\\n=>{input_txt_processed_indice}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    input_ids = torch.tensor(input_txt_processed_indice).to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        # Apply softmax to outputs to get probabilities\n",
    "        probabilities = F.softmax(outputs, dim=-1)  # (batch_size, seq_length, num_classes)\n",
    "        # Convert outputs to predicted labels by taking the argmax\n",
    "        predicted_labels = torch.argmax(probabilities, dim=2)  # (batch_size, seq_length)\n",
    "        predictions = predicted_labels.cpu().numpy().squeeze()\n",
    "\n",
    "        pad_index_from = np.where(input_txt_processed_indice[0] == 1993)[0][0]\n",
    "        predictions = predictions[:pad_index_from].tolist()\n",
    "\n",
    "        result_spacing = make_pred_sents(list(input_txt_processed_no_space[0]), predictions)\n",
    "        print(f'{input_txt}\\n=>{input_txt_processed_no_space}\\n=>{result_spacing}\\n=>{predictions}')        \n",
    "\n",
    "    return result_spacing, predictions\n",
    "\n",
    "\n",
    "# 추론 실행\n",
    "input_txt = '아 버 지가 방에 들어 가 신다'\n",
    "result_spacing, predictions = inference(model, input_txt, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729df98",
   "metadata": {},
   "source": [
    "# pip pachage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74f4d738",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# import\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import json\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils import CharLevelLSTM, pre_processing, encoding_and_padding, load_vocab, pad_sequences, make_pred_sents, inference\n",
    "\n",
    "root_folder = './resources'\n",
    "## config\n",
    "rules_path = os.path.join(root_folder, 'rules.json')\n",
    "vocab_path = os.path.join(root_folder, 'w2idx.dic')\n",
    "model_path = os.path.join(root_folder, 'space_model.pth')\n",
    "\n",
    "# model_path = pkg_resources.resource_filename(\n",
    "#     'korspacing', os.path.join('resources', 'space_model.pth'))\n",
    "# vocab_path = pkg_resources.resource_filename(\n",
    "#     'korspacing', os.path.join('resources', 'dicts', 'c2v.dic'))\n",
    "\n",
    "max_seq_len = 200\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "config_model_vocab_size = 1994\n",
    "config_model_embed_dim = 256\n",
    "config_model_num_filters = 128\n",
    "config_model_filter_sizes = [2, 3, 4, 5]  # 다양한 크기의 필터 사용\n",
    "config_model_hidden_dim = 256\n",
    "config_model_output_dim = 2  # binary\n",
    "config_model_dropout = 0.3\n",
    "config_model_num_layers = 3\n",
    "config_model_pad_token=1993  # padding 무시하고 loss를 구하기 위해\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CharLevelLSTM(config_model_vocab_size, config_model_embed_dim, config_model_hidden_dim, config_model_output_dim, config_model_num_layers, config_model_dropout)\n",
    "model.load_state_dict(torch.load(model_path));  # Best 상태로 모델을 로드\n",
    "model.eval()\n",
    "model.to(device);\n",
    "\n",
    "# 사전 파일 로딩\n",
    "w2idx, idx2w = load_vocab(vocab_path)  # 1994, w2idx: '엠': 1352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe436460",
   "metadata": {
    "code_folding": [
     0,
     5,
     22
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## rules ##\n",
      "{'아버지 가방에': '아버지가 방에'}\n",
      "아버지가 방 에 들 어 가 신 다\n"
     ]
    }
   ],
   "source": [
    "## KorSpacing class\n",
    "class KorSpacing:\n",
    "    '''\n",
    "    run korean word spacing by torch\n",
    "    '''\n",
    "    def __init__(self, rules=True, verbose=False):\n",
    "        self.w2idx = w2idx\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.device = device\n",
    "        self.verbose = verbose        \n",
    "        self.model = model\n",
    "        \n",
    "        # rules가 dictionary면 바로 읽고, 경로면 dictionary를 읽어온다\n",
    "        if type(rules)==dict:\n",
    "            self.rules = rules\n",
    "        elif rules==True:\n",
    "            with open(rules_path, 'r', encoding='UTF-8') as f_read:\n",
    "                self.rules = json.load(f_read)\n",
    "                \n",
    "        print('## rules ##')\n",
    "        pprint(self.rules)\n",
    "\n",
    "    def __call__(self, input_txt):\n",
    "        \n",
    "        # 띄어쓰기 제거\n",
    "        input_txt_nospace = input_txt.replace(\" \", \"\")\n",
    "        \n",
    "        if len(input_txt_nospace) > self.max_seq_len:\n",
    "            splitted_sent = [input_txt_nospace[:self.max_len]]\n",
    "        else:\n",
    "            splitted_sent = [input_txt_nospace]\n",
    "        \n",
    "        input_txt_processed = pre_processing(splitted_sent)  # ['«아버지가^방에^들어^가^신다»']\n",
    "        input_txt_processed_no_space = [tmp.replace('^', '') for tmp in input_txt_processed]  # ['«아버지가방에들어가신다»']\n",
    "\n",
    "        input_txt_processed_indice = encoding_and_padding(word2idx_dic=self.w2idx,\n",
    "                                      sequences=input_txt_processed_no_space,\n",
    "                                      maxlen=self.max_seq_len,\n",
    "                                      padding='post',\n",
    "                                      truncating='post')  # [[   3,   26,  188,   12,   11,  118,    7,   29,   20,   11,   70, 2,   4, 1993, 1993,\n",
    "        input_ids = torch.tensor(input_txt_processed_indice).to(device)\n",
    "        \n",
    "        # run model\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids)\n",
    "            # Apply softmax to outputs to get probabilities\n",
    "            probabilities = F.softmax(outputs, dim=-1)  # (batch_size, seq_length, num_classes)\n",
    "            # Convert outputs to predicted labels by taking the argmax\n",
    "            predicted_labels = torch.argmax(probabilities, dim=2)  # (batch_size, seq_length)\n",
    "            predictions = predicted_labels.cpu().numpy().squeeze()\n",
    "\n",
    "            pad_index_from = np.where(input_txt_processed_indice[0] == 1993)[0][0]\n",
    "            predictions = predictions[:pad_index_from].tolist()\n",
    "\n",
    "            result_spacing = make_pred_sents(list(input_txt_processed_no_space[0]), predictions)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f'{input_txt}\\n=>{input_txt_nospace}\\n=>{input_txt_processed_no_space}\\n=>{result_spacing}\\n=>{predictions}')        \n",
    "\n",
    "        # rule 적용\n",
    "        if len(self.rules)>0:\n",
    "#             print('# rule #')\n",
    "            for word, rgx in rules.items():\n",
    "                result_spacing = result_spacing.replace(word, rgx)\n",
    "        \n",
    "        return result_spacing.strip()\n",
    "\n",
    "# from korspacing import KorSpacing\n",
    "\n",
    "rules = {\n",
    "    '아버지 가방에': '아버지가 방에', \n",
    "    '아 버지가방': '아버지가 방',     \n",
    "}\n",
    "\n",
    "# spacing = KorSpacing(rules=rules)\n",
    "spacing = KorSpacing()\n",
    "result = spacing('아버지가방에들어가신다')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf3ef268",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## rules ##\n",
      "{'아버지 가방에': '아버지가 방에'}\n",
      "아버지가 방 에 들 어 가 신 다\n",
      "## rules ##\n",
      "{'아버지 가방에': '아버지가 방에'}\n",
      "아버지가 방 에 들 어 가 신 다\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "from korspacing import KorSpacing\n",
    "\n",
    "rules = {\n",
    "    '아버지 가방에': '아버지가 방에', \n",
    "    '아 버지가방': '아버지가 방',     \n",
    "}\n",
    "\n",
    "# spacing = KorSpacing(rules=rules)\n",
    "spacing = KorSpacing()\n",
    "\n",
    "result = spacing('아버지가방에들어가신다')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfea31",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d440f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031779bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
